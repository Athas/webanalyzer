
\documentclass[a4paper,oneside,article]{memoir}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage[utf8]{inputenc}
\usepackage[danish]{babel}
\usepackage[garamond]{mathdesign}
\usepackage{url}
\usepackage{graphicx}
\usepackage{pdflscape}
\usepackage{longtable}

\DeclareTextFontCommand{\textfleur}
{\fontencoding{T1}\fontfamily{FleurCornerCaps}\selectfont}


\renewcommand{\ttdefault}{pcr} % bedre typewriter font
\renewcommand{\rmdefault}{ugm} % garamond

\usepackage{lettrine}

%\overfullrule=5pt

%\setsecnumdepth{part}

\title{Testspecifikation  \\ \small{Førsteårsprojekt}}

\author
{
  Gruppe 1:\\
  Troels Henriksen (athas@sigkill.dk)\\
  Jesper Reenberg (reenberg@kampsax.dtu.dk)\\
  Martin Dybdal (dybber@dybber.dk)\\ \\
  Vejledere: Dina og Kasper
}


\setcounter{tocdepth}{2}
\setcounter{secnumdepth}{0}

\pagestyle{plain}

\date{\today}

\begin{document}
\maketitle
\newpage
\tableofcontents*
\newpage

\renewcommand\arraystretch{1.2} % større tabel-celler, placeret så det
                                % ikke ødelægger forsiden


% Testspecifikationen SKAL beskrive:

% * planlægning af testen, herunder jeres mål med testen og hvad I
% finder særligt kritisk for jeres projekt at få testet;

% * resultaterne af testen, herunder hvilke fejl er udbedret og hvilke
% fejl findes stadig i programmet;

% * en test af funktionalitet, herunder hvordan I har genereret
% testeksempler, indholdet af testeksemplerne (fortløbende
% nummereret), resultaterne fra kørsel af testeksempler;

% * en test af brugsvenlighed, herunder en begrundelse for valg af
% evalueringsteknik, en liste over de brugsvenlighedsproblemer som er
% identificeret (fortløbende nummereret), en beskrivelses af hvordan
% de kan løses.

% Bedømmelsen af testspecifikationen fokuserer på at I: (a) har
% besvaret alle fire punkter ovenfor, (b) har planlagt testen med
% hensyntagen til jeres projekts fokus, (c) ved jeres test dækker
% samtlige krav, dvs. har mindst et testeksempel for hvert krav, (d)
% har genereret testeksempler systematisk, (e) har beskrevet løsninger
% på væsentlige funktionalitets- og brugsvenlighedsproblemer, (f) har
% lavet jeres brugsvenlighedsevaluering baseret på realistiske
% opgaver, (g) har fundet fejl ? både i funktionstesten og ved
% evalueringen af brugsvenlighed ? eller har en overbevisende
% forklaring på hvorfor ingen fejl blev fundet.

% Upload filen i jeres gruppes folder. Testspecificationen skal
% afleveres som ét dokument og oploades i pdf-format (navn
% "Testspecifikation") senest den 6. juni 2007.
 

\chapter{Strategi}
Vores test er delt i tre dele, hvor de to første omhandler
funktionstests og den sidste omhandler brugertests. Den første del ---
funktionstest af vores krav --- skal afgøre om programmet opfylder de
krav vi har stillet i kravspecifikationen og at alle disse funktioner
virker korrekt. Hvor kravene ikke er opfyldt (måske fordi det er
blevet besluttet at de ikke var værd at implementere) vil dette blive
noteret. Det optimale ville være hvis denne afprøvning kunne
automatiseres, men i de fleste af testene vil det, grundet vores
output i form af menneske--orienteret HTML, ikke kunne lade sig gøre
uden at bruge mere tid på det end vi har tilgængelig. Hvis man
eksempelvis vil automatisere afprøvning af LIX-tal implementationen
ville det teoretisk kunne gøres ved at analysere programmets
HTML-output (evt. via et XML--querysprog), men da outputformatet ikke
er fast defineret vil det for det første være en yderst skrøbelig
blackbox--test, og for det andet være uhyre besværligt. For næsten alle
funktionstestene vil der være en test af ugyldig inddata, for at se om
programmet giver en brugbar fejlmeddelelse. Vi har dog valgt at samle
dette under et afsnit. Den anden del af testen omhandler
funktionstests som er sværere at knytte direkte til et krav, men som
stadigvæk er vigtige for programmets korrekte virkemåde.

Den tredje del af testen --- brugertesten --- skal bruges til at finde
ud af om brugervejledningen er forståelig og om brugeren kan finde ud
af at bruge programmet ved at læse brugermanualen. Derudover skal
testen bruges til at finde ud af om resultatsiderne er vanskelige at
læse.

Bemærk at en del tests omhandler muligheden for at brugeren kan slå
dele af analysen fra --- i disse tilfælde vil det ikke blive testet at
den relevante del ikke bliver slået fra når det ikke er angivet ---
f.eks. vil det i forbindelse med afprøvningen af muligheden for at slå
LIX-tal fra ikke også blive afprøvet at LIX--tal bliver vist når de
ikke er slået fra, og når det testes at stavefejl angivet som
forkortelser ikke bliver markeret som stavefejl testes det
\textit{ikke} om forkert stavede ord markeres som stavefejl, når de
ikke er angivet som forkortelser. Det forventes at de dedikerede tests
for den relevante feature vil afprøve dette generelle scenarie. Det
testes altså ikke hvad der sker når features \textit{ikke} aktiveres.

Det absolut vigtigste funktionalitet i vores program er naturligvis
den korrekte omdannelse af HTML-dokumenter til parsetræer, leksikalske
enheder og analyseresultater - det er vigtigt at analyserne er
korrekte, og for at de kan være det er det nødvendigt at opdelingen i
sætninger og ord er korrekt. Derfor vil vi gå mere op i at afprøve
denne funktionalitet end mere undværlige features som de forskellige
konfigurationsmuligheder.

Kørselsresultater, såvel som inddata, er at finde sammen med vores
kode i mappen \texttt{functionalitytesting}

\chapter{Kravtest}

Vi vil systematisk gennemgå de krav vi har stillet til vores programs
funktionalitet og beskrive hvorledes hvert enkelt krav kan
afprøves. Vi henviser til kravspecifikationen for en uddybning af
kravene, følgende afsnit vil kun omhandle hvorledes de kan testes.

\begin{landscape}
\section{Krav 1: Analyse af et helt websted}
Det testrelevante i dette krav er programmets evne til at følge links
rundt på det angivne website, og ikke at følge links der fører ud fra
websitet. Andre tests dækker hvorvidt den resulterende analyse er
korrekt, formålet med denne test er udelukkende at undersøge om alle
sider rent faktisk bliver besøgt. Det er også relevant at sikre at
sider ikke bliver analyseret mere end én gang, og at cirkulære links
(side \textit{A} linker til side \textit{B} der igen linker tilbage
til side \textit{A}). ikke forårsager at programmet går i et uendeligt
loop. Det kan ses hvilke sider der er blevet analyseret ved at se på
den genererede side--liste, hvilket betyder at denne test er afhængig
af at HTML--output (krav 6) fungerer korrekt.

\subsubsection{Resultater}
%\setlength\LTleft{0pt}
%\setlength\LTright{0pt}
\begin{longtable}[c]{p{20pt}|p{220pt}|p{130pt}|p{130pt}|r}
\textbf{Nr.} &
\textbf{Inddata} &
\textbf{Forventet resultat} &
\textbf{Faktisk resultat} &
\textbf{Konklusion} \\ \hline

1 &
Et website der ikke indeholder links, og kun én side. &
Kun den ene side analyseres. &
Som forventet. &
$\surd$ \\ \hline

2 &
Et website der ikke indeholder interne links, men links til
sider på andre websites. &
Kun websitets egen sider skal analyseres &
Som forventet. &
$\surd$ \\ \hline

3 &
Et website der indeholder interne links uden cirkularitet, og
hvor hver side kun kan findes af én sti. &
Alle tilgængelige sider skal analyseres. &
Som forventet. &
$\surd$ \\ \hline

4 &
Et website der indeholder interne links uden cirkularitet, og hvor
hver side kan tilgås af flere forskellige veje. &
De tilgængelige sider skal kun analyseres én gang hver. &
Som forventet. &
$\surd$ \\ \hline

5 &
Et website der indeholder interne links med cirkulære links. &
Hver side skal kun analyseres én gang, og programmet skal
terminere. &
Som forventet. &
$\surd$

\end{longtable}

\begin{longtable}[c]{p{20pt}|p{220pt}|p{130pt}|p{130pt}|r}
\textbf{Nr.} &
\textbf{Inddata} &
\textbf{Forventet resultat} &
\textbf{Faktisk resultat} &
\textbf{Konklusion} \\ \hline

% skabelon
testnr &
inddata &
forventet &
faktisk &
konklusion \\ \hline
\end{longtable}

\subsection{Krav 1.1: Respekter robots.txt}

Programmet skal tjekke det angivne websteds robots.txt og sørge for at
sider angivet i filen ikke bliver hentet og analyseret. Det giver kun
mening at teste dette krav såfremt det er sikret at krav 1 (og krav 6)
virker korrekt. Undersøgelsen af hvilke sider der ender med at blive
analyseret kan foregå på samme måde som i krav 1.

I de angivne tests adskilles der ikke mellem forbud hvor alle
web--crawlere har forbud mod at besøge en side, og de, hvor vores
program specifikt har forbud. Vi opfatter denne distinktion som så
teknisk at den i højere grad hører hjemme i whitebox unit--tests, især
fordi denne distinktion ikke er nævnt i krav 1.1.

\begin{longtable}[c]{p{20pt}|p{220pt}|p{130pt}|p{130pt}|r}
\textbf{Nr.} &
\textbf{Inddata} &
\textbf{Forventet resultat} &
\textbf{Faktisk resultat} &
\textbf{Konklusion} \\ \hline

6 &
Et website, der ikke har en robots.txt--fil &
Alle tilgængelige sider analyseres &
Som forventet &
$\surd$ \\ \hline

7 &
Et website hvor programmet har forbud mod at besøge nogen sider
overhovedet &
Ingen sider bliver analyseret, programmet giver en fejlmeddelelse. &
Som forventet &
$\surd$ \\ \hline

8 &
Et website hvor programmet har forbud mod at besøge en side der har
eksklusive links til undersider på det analyserede website. &
Den forbudte side analyseres ikke, og ej heller gør de sider som kun
er tilgængelige via den forbudte side &
Som forventet &
$\surd$ \\ \hline

9 &
Et website hvor programmet har forbud mod at besøge en side der har
ikke--eksklusive links til undersider (som kan tilgås via andre,
ikke--forbudte, sider) på det analyserede website. &
Den forbudte side analyseres ikke, men det gør de sider som den linker
til. &
Som forventet &
$\surd$ \\ \hline

\end{longtable}

\subsection{Krav 1.2: Dybde af crawling}
Hvis man angiver en maksimal dybde af analysen (reelt, hvor dybt links
skal følges, idet forsiden er dybde 0), så skal programmet respektere
denne og gøre det korrekt.

\begin{longtable}[c]{p{20pt}|p{220pt}|p{130pt}|p{130pt}|r}
\textbf{Nr.} &
\textbf{Inddata} &
\textbf{Forventet resultat} &
\textbf{Faktisk resultat} &
\textbf{Konklusion} \\ \hline

10 &
Ingen angivet dybde og et 3 sider dybt website &
Alle sider skal analyseres. &
Som forventet &
$\surd$ \\ \hline

11 &
Maksimal dybde 0 angivet og et 3 sider dybt website &
Kun den øverste side (forsiden) skal analyseres &
Som forventet &
$\surd$ \\ \hline

12 &
Maksimal dybde 1 angivet og et 3 sider dybt website &
Alle sider, med undtagelse af de(n) dybeste side, skal analyseres &
Som forventet &
$\surd$ \\ \hline

13 &
Maksimal dybde 1 angivet og et 3 sider dybt website, hvor en side har
både dybde 2 og dybde 1. Hvis sider bliver undersøgt i den rækkefølge de
bliver set i vil den først blive undersøgt som dybde 2. &
Alle sider op til dybde 2 skal analyseres, og den nævnte side der både
har dybde 2 og dybde 1 skal også analyseres. &
Som forventet &
$\surd$ \\ \hline

\end{longtable}

\section{Krav 2: Analysemetoder}

Dette krav kan i sig selv ikke testes, da det fungerer som
``paraplykrav'' for 3 underkrav. Disse kan dog alle testes på omtrent
samme måde. En side med indhold der er repræsentativt for en
ækvivalensklasse (og som opfylder andre krav som
f.eks. tegnindkodning) analyseres, og programmets output sammenlignes
med det ønskede resultat. Denne test er således afhængig af at krav 6
omkring HTML-output er korrekt. Langt størsteparten af disse tests er
baseret på korrekt at opdele tegnfølgerne på HTML-sider i afsnit,
sætninger og ord, og at teste uddybende, selv med ækvivalensklasser,
ville være en ekstremt omfangsrig opgave som vi hverken har tid eller
grammatisk viden til at udføre. Derfor vil tests af opdelingen i ord
og sætninger være rimeligt rudimentær. Det er også værd at notere at
det fra et whitebox--perspektiv er unødvendigt at teste korrekt
leksikalsk analyse for både LIX og FKRT, idet programmet er
implementeret således at at opdelingen i leksikalske enheder er
uafhængig af analysemetoderne, men fra et blackbox perspektiv, som
disse tests er designet ud fra, kan man ikke gå ud fra at det er
tilfældet.

Når vi i det følgende henfører til at noget bliver ``markeret'' i
programmets output (f.eks. ``markering af stavefejl'') henfører vi til
brugervejledningen for en beskrivelse af hvordan denne markering helt
præcist ser ud.

\subsection{Krav 2.1: Læsbarhedsindeks, LIX}

Det essentielle i dette krav er at teksten korrekt opdeles i sætninger
og ord, og at det resulterende LIX-tal er korrekt. Idet vores
outputformat ikke angiver LIX-tal for hver enkelt sætning kan denne
sammenligning kun foregå for hele tekstafsnit, men vi er i stand til
at bedømme om sætningsopdeling sker korrekt.

\begin{longtable}[c]{p{20pt}|p{220pt}|p{130pt}|p{130pt}|r}
\textbf{Nr.} &
\textbf{Inddata} &
\textbf{Forventet resultat} &
\textbf{Faktisk resultat} &
\textbf{Konklusion} \\ \hline

14 &
En side uden indhold &
Programmet skal køre som normalt, men output skal naturligvis ikke
indeholde analyse af nogen specifik tekst &
? &
? \\ \hline

15 & 
En side med et enkelt afsnit indeholdende en enkelt simpel sætning. &
Ordene i sætningen skal opdeles korrekt og det beregnede LIX-tal skal
ligeledes være korrekt. &
? &
? \\ \hline

16 & 
En side med et enkelt afsnit indeholdende en enkelt kompliceret
sætning indeholdende parenteser, apostroffer og citationer (som ikke
adskiller sætninger). &
Ordene i sætningen skal opdeles korrekt og det beregnede LIX-tal skal
ligeledes være korrekt. &
? &
? \\ \hline

17 &
En side med et enkelt afsnit indeholdende adskillige
komplicerede sætninger indeholdende parenteser, apostroffer og
citationer (som ikke adskiller sætninger). &
Sætningerne i afsnittet og ordene i sætningerne skal opdeles korrekt
og det beregnede LIX-tal skal ligeledes være korrekt. &
? &
? \\ \hline

18 &
En side med adskllige afsnit indeholdende adskillige
komplicerede sætninger indeholdende parenteser, apostroffer og
citationer (som ikke adskiller sætninger). &
Afsnittene på siden, sætningerne i afsnittene og ordene i sætningerne
skal opdeles korrekt og det beregnede LIX-tal skal ligeledes være korrekt. &
? &
? \\ \hline

\end{longtable}

\subsection{Krav 2.2: Flesch-Kincaid Readability Test (FKRT)}

Det essentielle i dette krav er at teksten korrekt opdeles i sætninger
og ord, og at de resulterende FRE- og FKGL-tal er korrekte. Idet vores
outputformat ikke angiver disse værdier for hver enkelt sætning kan
denne sammenligning kun foregå for hele tekstafsnit, men vi er i stand
til at bedømme om sætningsopdeling sker korrekt.

\begin{longtable}[c]{p{20pt}|p{220pt}|p{130pt}|p{130pt}|r}
\textbf{Nr.} &
\textbf{Inddata} &
\textbf{Forventet resultat} &
\textbf{Faktisk resultat} &
\textbf{Konklusion} \\ \hline

19 &
En side uden indhold &
Programmet skal køre som normalt, men output skal naturligvis ikke
indeholde analyse af nogen specifik tekst &
? &
? \\ \hline

20 & 
En side med et enkelt afsnit indeholdende en enkelt simpel sætning. &
Ordene i sætningen skal opdeles korrekt og de beregnede FKRT-værdier skal
ligeledes være korrekte. &
? &
? \\ \hline

21 & 
En side med et enkelt afsnit indeholdende en enkelt kompliceret
sætning indeholdende parenteser, apostroffer og citationer (som ikke
adskiller sætninger). &
Ordene i sætningen skal opdeles korrekt og de beregnede FKRT-værdier
skal ligeledes være korrekt. &
? &
? \\ \hline

22 &
En side med et enkelt afsnit indeholdende adskillige
komplicerede sætninger indeholdende parenteser, apostroffer og
citationer (som ikke adskiller sætninger). &
Sætningerne i afsnittet og ordene i sætningerne skal opdeles korrekt
og de beregnede FKRT-værdier skal ligeledes være korrekt. &
? &
? \\ \hline

23 &
En side med adskllige afsnit indeholdende adskillige
komplicerede sætninger indeholdende parenteser, apostroffer og
citationer (som ikke adskiller sætninger). &
Afsnittene på siden, sætningerne i afsnittene og ordene i sætningerne
skal opdeles korrekt og de beregnede FKRT-værdier skal ligeledes være korrekt. &
? &
? \\ \hline

\end{longtable}

\subsection{Krav 2.3: Stavekontrol}

Hvis en side er angivet til dansk og en dansk ordbog til
\texttt{aspell} (samt naturligvis selve programmet \texttt{aspell}) er
installeret, så skal programmet kunne tjekke for stavefejl. I vores
krav angiver vi ikke hvorledes stavekontrollen er implementeret, men i
vores dokumentation beskriver vi at systemets
\texttt{aspell}-installation benyttes, derfor mener vi at det er
korrekt at basere blackbox-tests på eksistensen af
\texttt{aspell}. Som med FKRT-- og LIX--testene er afprøvning af
stavekontrollen baseret på at køre programmet på en side og
sammenligne resultatet med det korrekte resultat. Idet vi erkender at
\texttt{aspell} ikke er perfekt tager vi forbehold for at der er en
stor klasse af gyldige ord som vil blive markeret som forkerte. Vi
kræver blot at vores program angiver de samme ord som forkert stavede
som \texttt{aspell} ville hvis \texttt{aspell} blev kørt direkte.

\begin{longtable}[c]{p{20pt}|p{220pt}|p{130pt}|p{130pt}|r}
\textbf{Nr.} &
\textbf{Inddata} &
\textbf{Forventet resultat} &
\textbf{Faktisk resultat} &
\textbf{Konklusion} \\ \hline

24 &
Side med dansk tekst på en maskine der ikke har \texttt{aspell}
installeret. &
Brugeren informeres om problemet men programmet fortsætter, ingen ord
markeres som forkert stavede. &
Som forventet. &
$\surd$ \\ \hline

25 &
Side med dansk tekst på en maskine der har \texttt{aspell}
installeret, men ingen dansk ordbog. &
Ingen ord markeres som forkert stavede. &
Som forventet. &
$\surd$ \\ \hline

26 &
Side med dansk tekst indeholdende både korrekt og ukorrekt stavede ord
på en maskine der har \texttt{aspell}
og en dansk ordbog installeret. &
Ord markeres efter deres korrekthed. &
Som forventet. &
$\surd$ \\ \hline

\end{longtable}

\subsection{Krav 2.3.1: Flere sprog}

Det skal testes at programmet fungerer med en ikke-dansk
\texttt{aspell}-ordbog. Krav 2.3-testen udføres for to forskellige
sider indeholdende hhv. engelsk og tysk tekst.

\begin{longtable}[c]{p{20pt}|p{220pt}|p{130pt}|p{130pt}|r}
\textbf{Nr.} &
\textbf{Inddata} &
\textbf{Forventet resultat} &
\textbf{Faktisk resultat} &
\textbf{Konklusion} \\ \hline

27 &
Side med engelsk tekst på en maskine der ikke har \texttt{aspell}
installeret. &
Brugeren informeres om problemet men programmet fortsætter, ingen ord
markeres som forkert stavede. &
Som forventet. &
$\surd$ \\ \hline

28 &
Side med engelsk tekst på en maskine der har \texttt{aspell}
installeret, men ingen engelsk ordbog. &
Ingen ord markeres som forkert stavede. &
Som forventet. &
$\surd$ \\ \hline

29 &
Side med engelsk tekst indeholdende både korrekt og ukorrekt stavede ord
på en maskine der har \texttt{aspell} og en engelsk ordbog
installeret. &
Ord markeres efter deres korrekthed. &
Som forventet. &
$\surd$ \\ \hline

30 &
Side med tysk tekst på en maskine der ikke har \texttt{aspell}
installeret. &
Brugeren informeres om problemet men programmet fortsætter, ingen ord
markeres som forkert stavede. &
Som forventet. &
$\surd$ \\ \hline

31 &
Side med tysk tekst på en maskine der har \texttt{aspell}
installeret, men ingen tysk ordbog. &
Ingen ord markeres som forkert stavede. &
Som forventet. &
$\surd$ \\ \hline

32 &
Side med tysk tekst indeholdende både korrekt og ukorrekt stavede ord
på en maskine der har \texttt{aspell} og en tysk ordbog installeret. &
Ord markeres efter deres korrekthed. &
Som forventet. &
$\surd$ \\ \hline

\end{longtable}

\subsection{Krav 2.4: Gentagne ord}

Det skal testes at to på hinanden følgende identiske ord på en side
markeres som gentagne ord, dog ikke hvis de befinder sig i forskellige
sætninger. Alle følgende tests kan godt udføres med samme
HTML-dokument.

\begin{longtable}[c]{p{20pt}|p{220pt}|p{130pt}|p{130pt}|r}
\textbf{Nr.} &
\textbf{Inddata} &
\textbf{Forventet resultat} &
\textbf{Faktisk resultat} &
\textbf{Konklusion} \\ \hline

33 &
To på hinanden følgende ord, som ikke er ens &
De to ord skal ikke markeres som gentagne ord &
Som forventet &
$\surd$ \\ \hline

34 &
To på hinanden følgende ord, som er ens, og som befinder sig i samme
sætning &
De to ord skal markeres som gentagne ord &
Som forventet &
$\surd$ \\ \hline

35 &
To på hinanden følgende ord, som er ens, og som befinder sig i
to forskellige sætninger (adskilt af punktum, udråbstegn, osv) &
De to ord skal ikke markeres som gentagne ord &
Som forventet &
$\surd$ \\ \hline

\end{longtable}

\subsection{Krav 2.5: Beregning af sidesværhedsgrad}
Ved en blackbox test kan vi ikke teste at der bliver beregnet en
sidesværhedsgrad, da vi har valgt ikke at vise sidesværhedsgraden på
siden, men bare brugt den til at farve og sortere siderne
efter. Ydermere er sidesværhedsgraden ikke en kravdefineret
størrelse. Beregningen af sidesværhedsgraden er baseret på LIX- og
FKRT-resultaterne, så afprøvning af dette krav giver kun mening hvis
afprøvningen af LIX- og FKRT- er positiv.

Vi kan i stedet teste at oversigtssiden bliver sorteret efter sidernes
sværhedsgrad. Dette kræver dog at vi på forhånd har en idé om den
``rette'' sidesværhedsgrad for en enkelt side, hvilket betyder af
afprøvningen af dette bliver lidt vag og ulden i kanten fordi det er
nødvendigt at inddrage sider som har ``åbenlyst svær'' og ``åbenlyst
nem'' tekst. Idet sidesværhedsgraden kun bruges til at sortere
resultaterne er det dog ikke kritisk at den er hundrede procent
eksakt, og vi mener derfor også at vi kan slippe afsted med en så
informel test som vi udfører her.

\begin{longtable}[c]{p{20pt}|p{220pt}|p{130pt}|p{130pt}|r}
\textbf{Nr.} &
\textbf{Inddata} &
\textbf{Forventet resultat} &
\textbf{Faktisk resultat} &
\textbf{Konklusion} \\ \hline

36 &
En website indeholdende tre sider, hvoraf en er ``åbenlyst svær'', en
er ``åbenlyst nem'' og den tredje er mellemsvær. &
Den svære side skal tildeles den højeste sidesværhedsgrad, den
mellemsvære en lavere sidesværhedsgrad, og den nemme den laveste
sidesværhedsgrad. &
Som forventet &
$\surd$ \\ \hline

\end{longtable}

\section{Krav 3: Analyse baseret på HTML-tags}

Dette krav kan ikke testes for sig selv, idet det fungerer som
``paraplykrav'' for en række mere specifikke underkrav der omhandler
behandling af specifikke HTML-tags. Afprøvning af disse underkrav
foregår alle på samme måde --- for hvert underkrav produceres en side
indeholdende repræsentanter for de relevante ækvivalensklasser,
programmet køres på disse sider, og resultatet sammenlignes med det
forventede. Det er ikke nødvendigt at lave en side for hver eneste
ækvivalensklasse. Disse krav afhænger af at krav 2 og krav 8 er
opfyldt og fungerer korrekt.

\subsection{Krav 3.1: \texttt{em} og \texttt{strong}}

Dette krav har vi valgt ikke at opfylde, da vi under implementationen
af vores program nåede frem til den vurdering at det ikke ville
forbedre analysen på en meningsfyldt måde. Det vil derfor ikke blive
testet.

\subsection{Krav 3.2: \texttt{hN}}

Dette krav har vi valgt ikke at opfylde, da vi under implementationen
af vores program nåede frem til den vurdering at det ikke ville
forbedre analysen på en meningsfyldt måde. Det vil derfor ikke blive
testet.

\subsection{Krav 3.3: \texttt{abbr} og \texttt{acronym}}

I det følgende opfattes et ord som værende ``angivet som forkortelse''
hvis det befinder sig i et \texttt{abbr}- eller
\texttt{acronym}-tag. Det skal testes at ord, der normalt ville
markeres som stavefejl i det sprog som sidens tekst er angivet til at
være skrevet i, ikke bliver opfattet som stavefejl hvis de er angivet
som forkortelser. Dette krav er afhængigt af at krav 2.3 er opfyldt og
fungerer. Følgende ækvivalensklasser repræsenterer forekomster i en
test-side, og kan godt alle findes i samme test-side for at lette
afprøvningen.

\subsubsection{Ækvivalens-klasser}
\begin{itemize}
\item Korrekt stavede ord der ikke er angivet som forkortelser skal
  ikke markeres som stavefejl (muligvis redundant ift. krav 2.3).
\item Forkert stavede ord der er angivet som forkortelser skal ikke
  markeres som stavefejl.
\item Korrekt stavede ord der er angivet som forkortelser skal ikke
  markeres som stavefejl.
\end{itemize}

\begin{longtable}[c]{p{20pt}|p{220pt}|p{130pt}|p{130pt}|r}
\textbf{Nr.} &
\textbf{Inddata} &
\textbf{Forventet resultat} &
\textbf{Faktisk resultat} &
\textbf{Konklusion} \\ \hline

37 &
Et forkert stavet ord, der er angivet som forkortelse &
Ordet skal ikke markeres som stavefejl. &
Som forventet &
$\surd$ \\ \hline

38 &
Et korrekt stavet ord, der er angivet som forkortelse &
Ordet skal ikke markeres som stavefejl. &
Som forventet &
$\surd$ \\ \hline

\end{longtable}

\subsection{Krav 3.4: Citater skal ikke analyseres.}

Citater skal ikke medtages når sidesværhedsgraden beregnes. Afprøvning
af dette foregår ved at fjerne den citerede tekst og undersøge om der
bliver beregnet samme sidesværhedsgrad som når den citerede tekst er
der. Denne afprøvningsmetode fungerer kun fordi stavefejl ikke
påvirker sidesværhedsgraden, og derfor burde det ikke påvirke
resultatet at citater indeholdende stavefejl fjernes.

\begin{longtable}[c]{p{20pt}|p{220pt}|p{130pt}|p{130pt}|r}
\textbf{Nr.} &
\textbf{Inddata} &
\textbf{Forventet resultat} &
\textbf{Faktisk resultat} &
\textbf{Konklusion} \\ \hline

39 &
En side indeholdende et afsnit som er designeret som et citat
via \texttt{blockquote}) og som ikke indeholder stavefejl &
Sidesværhedsgraden skal være den samme om citatet findes på siden
eller ej, men når citatet findes skal det vises i output &
Som forventet &
$\surd$ \\ \hline

40 &
En side indeholdende et afsnit som er designeret som et citat (via
\texttt{blockquote}) og som indeholder stavefejl &
Sidesværhedsgraden skal være den samme om citatet findes på siden
eller ej, men hvis citatet findes skal det vises i output og de
forkert stavede ord skal være markeret &
Som forventet &
$\surd$ \\ \hline

\end{longtable}

\subsection{Krav 3.5: Tekst i andre sprog angivet med
  (\texttt{lang})}

Det skal testes at ord, der har fået et sprog angivet via
HTML-attributten \texttt{lang} bliver stavekontrolleret efter det
angivne sprog, om muligt, og hvis det angivne sprog ikke kendes, at
ordene ikke markeres som værende stavet forkert. Følgende
ækvivalensklasser repræsenterer forekomster i en test-side, og kan
godt alle findes i samme test-side for at lette afprøvningen.

\subsubsection{Ækvivalens-klasser}
\begin{itemize}
\item Et ord angivet med en ugyldig sprogkode skal ikke
  stavekontrolleres, og ikke markeres som stavet forkert.
\item Et ord angivet med en ukendt sprogkode (en ordbog for sproget er
  ikke installeret) skal ikke stavekontrolleres, og ikke markeres som
  stavet forkert.
\item Et ord angivet med en kendt sprogkode (en ordbog for sproget er
  installeret) som er forskellig fra resten af sidens sprogkode, og
  hvor ordet ikke ville være korrekt i det sprog som resten af siden
  er skrevet i, men er korrekt indenfor det angivne sprog, skal
  stavekontrolleres, og ikke markeres som stavet forkert. Som i krav
  2.3 tages der forbehold for mangler i \texttt{aspell}'s ordbog.
\item Et ord angivet med en kendt sprogkode (en ordbog for sproget er
  installeret) som er forskellig fra resten af sidens sprogkode, og
  hvor ordet ikke ville være korrekt i det sprog som resten af siden
  er skrevet i, og ikke er korrekt indenfor det angivne sprog, skal
  stavekontrolleres, og markeres som stavet forkert.
\end{itemize}

\subsection{Krav 3.6: \texttt{kbd}, \texttt{var} og \texttt{code}}

Ord angivet med disse tags (herefter refereret til som ``kode-ord'')
bør ikke stavekontrolleres og ikke tælles med når sidesværhedsgraden
beregnes. Afprøvningen af dette er praktisk identisk med afprøvningen
af citat-håndteringen (se afprøvning af krav 3.4).

\subsubsection{Ækvivalens-klasser}
\begin{itemize}
\item En side hvori dele af sætninger er designeret som værende
  kode-ord, og disse kode-ord er korrekt stavede ord indenfor sidens
  angivne sprog, skal ikke ændre sidesværhedsgrad hvis de fjernes. Dog
  skal de stadigvæk være at finde i output.
\item En side hvori dele af sætninger er designeret som værende
  kode-ord, og disse kode-ord er ukorrekt stavede ord indenfor sidens
  angivne sprog, skal ikke ændre sidesværhedsgrad hvis de fjernes. Dog
  skal de stadigvæk være at finde i output, men ikke være markeret som
  stavefejl.
\end{itemize}

\subsection{Krav 3.7: \texttt{bdo}}

Det skal testes at ord angivet som havende ikke-standard tegnretning
(højre mod venstre) bliver vendt om før de bliver
stavekontrolleret. Ydermere skal det kontrolleres at kun det inderste
af på hinanden indlejrede \texttt{bdo}-tags benyttes til at finde
tekstretningen (to gange ``højre mod venstre'' giver altså ikke
``venstre mod højre''). Følgende ækvivalensklasser repræsenterer
forekomster i en test-side, og kan godt alle findes i samme test-side
for at lette afprøvningen.

\subsubsection{Ækvivalens-klasser}
\begin{itemize}
\item Ord angivet som værende skrevet med ``højre mod venstre''
  tegnretning, som ville være stavefejl i det aktuelle sprog hvis de
  ikke blev vendt, og som ikke ville være stavefejl i det aktuelle
  sprog hvis de blev vendt, skal ikke markeres som stavefejl.
\item Ord angivet som værende skrevet med ``højre mod venstre''
  tegnretning, som ville være stavefejl i det aktuelle sprog hvis de
  blev vendt, og som ikke ville være stavefejl i det aktuelle sprog
  hvis de ikke blev vendt, skal markeres som stavefejl.
\item Ord angivet som værende skrevet med ``højre mod venstre''
  tegnretning, som ville være stavefejl i det aktuelle sprog hvis de
  ikke blev vendt, og som ville være stavefejl i det aktuelle sprog
  hvis de blev vendt, skal markeres som stavefejl.
\item Ord angivet som værende skrevet med ``højre mod venstre''
  tegnretning, som ikke ville være stavefejl i det aktuelle sprog hvis
  de ikke blev vendt, og som ikke ville være stavefejl i det aktuelle
  sprog hvis de blev vendt, skal ikke markeres som stavefejl.
\end{itemize}

\section{Krav 4: Konfiguration af analyse}

Dette krav har vi af simplicitetshensyn slækket lidt på --- når
analyser ``slås fra'' udføres de stadigvæk, og benyttes stadigvæk i
beregningen af sidesværhedsgraden, men de vises ikke i programmets
output.

Kravet kræver også at man kan undtage elementer fra analyse baseret på
deres \texttt{id} og \texttt{class}-attributter. I vores
implementation endte vi med kun at understøtte frafiltrering baseret
på \texttt{id}-attributten, men til gengæld også understøtte
frafiltrering baseret på tagnavnet.

\subsubsection{Ækvivalens-klasser}
\begin{itemize}
\item Hvis visning af LIX-tal slås fra skal der ikke fremgå LIX-tal af
  programmets output.
\item Hvis visning af FKGL-tal slås fra skal der ikke fremgå FKGL-tal
  af programmets output.
\item Hvis visning af FRE-tal slås fra skal der ikke fremgå FRE-tal
  af programmets output.
\item Hvis stavekontrol slås fra, og en side der ikke indeholder
  stavefejl analyseres, skal ingen ord markeres som forkert stavede.
\item Hvis stavekontrol slås fra, og en side indeholdende stavefejl
  analyseres, skal ingen ord markeres som forkert stavede.
\item Hvis markering af gentagne slås fra, og en side der ikke
  indeholder gentagne ord analyseres, skal ingen ord markeres som
  gentagne.
\item Hvis markering af gentagne slås fra, og en side der indeholder
  gentagne ord analyseres, skal ingen ord markeres som gentagne.
\item Hvis det angives at elementer med et specifikt \texttt{id} ikke
  skal medtages i analysen, skal elementer med dette \texttt{id} ikke
  figurere i programmets output, og ikke medtages i beregning af
  sidesværhedsgraden for en side. Sidesværhedsgraden skal altså ikke
  blive påvirket af at disse elementer fjernes.
\item Hvis det angives at elementer med et af flere angivne
  \texttt{id}-værdier ikke skal medtages i analysen, skal elementer
  med en af disse \texttt{id}-værdier ikke figurere i programmets
  output, og ikke medtages i beregning af sidesværhedsgraden for en
  side. Sidesværhedsgraden skal altså ikke blive påvirket af at disse
  elementer fjernes. Dette tester at man kan frafiltrere baseret på
  flere forskellige \texttt{id}-værdier i én analyse.
\item Hvis det angives at elementer med et specifikt \texttt{id} ikke
  skal medtages i analysen, skal elementer der ikke har det angivne
  \texttt{id} figurere i programmets output, og medtages i beregning
  af sidesværhedsgraden for en side.
\item Hvis det angives at elementer med et specifikt tag ikke skal
  medtages i analysen, skal elementer med dette tag ikke figurere i
  programmets output, og ikke medtages i beregning af
  sidesværhedsgraden for en side. Sidesværhedsgraden skal altså ikke
  blive påvirket af at disse elementer fjernes.
\item Hvis det angives at elementer med et blandt flere angivne tags
  ikke skal medtages i analysen, skal elementer med et af disse tags
  ikke figurere i programmets output, og ikke medtages i beregning af
  sidesværhedsgraden for en side. Sidesværhedsgraden skal altså ikke
  blive påvirket af at disse elementer fjernes. Dette tester at det er
  muligt at frafiltrere mere end én type tag af gangen.
\item Hvis det angives at elementer med et specifikt tag ikke skal
  medtages i analysen, skal elementer der har et andet tag figurere i
  programmets output, og medtages i beregning af sidesværhedsgraden
  for en side.
\end{itemize}

\section{Krav 5: Kommandobaseret interface}
Det er temmelig åbentlyst hvad der skal testes her: det skal være
muligt at starte en analyse direkte fra en kommandolinje.

\section{Krav 6: Resultater i HTML-format.}
Det skal kontrolleres at resultaterne gemmes i HTML--format og at der
genereres en index--side der giver adgang til alle de analyserede
undersider.

\section{Krav 7: Platform}

Vi mener ikke at dette program kan testes på en systematisk måde ---
for det første er det vagt (af nødvendighed, det er meget svært at
definere en præcis platform), og for det andet er det ikke rimeligt at
forvente at vi har en meningsfyldt måde at reagere på u--understøttede
platforme i programmet. I vores kravspecifikation nævner vi som
eksempel at programmet kan køre på DIKU's maskiner, men da vores
program er afhængigt af en
SML/NJ\footnote{\url{http://www.smlnj.org/}}-installation (som ikke
findes på DIKU's system) kan dette heller ikke uden videre gøres.

\section{Krav 8: Håndtering af HTML/XHTML}

Det er ikke muligt at lave en dybdegående test af dette krav - mængden
af ækvivalensklasser indenfor gyldige HTML-dokumenter ville indeholde
alle permutationer af alle gyldige HTML-elementer, en ekstrem
størrelse. Derfor nøjes vi med at afprøve repræsentative elementer
(f.eks. minder \texttt{br} og \texttt{hr} en del om hinanden i brug),
og ikke inddrage hvert eneste tag. Vi placerer så at sige vores
ækvivalensklasser på element-niveau i stedet for på dokument-niveau.

Det gør det yderligere svært at black-box-teste dette at der ikke kan
trækkes en direkte linje fra HTML-parsetræet til programmets output,
så de testede ækvivalensklasser er nogen særligt udvalgte som ville
have en direkte effekt på analyseresultatet såfremt de ikke blev
parset ordentligt.

I vores krav nævner vi behovet for at tage særlig hånd om
\texttt{style} og \texttt{script}-elementer, idet disse kan indeholde
HTML-lignende tegn som kan forstyrre parseren. Under implementationen
fandt vi frem til at det ville være en fejlallokering af resourcer at
implementere dette, idet problemet var noget mere komplekst end først
antaget, og at det desuden ikke er så stort i praksis, idet mange
HTML-sider enten refererer til eksterne scripts og stylesheets, eller
omgiver dem med HTML-kommentarer for ikke at forvirre ældre
browsere. Disse features vil således ikke blive testet.

\subsection{Ækvivalens-klasser}
\begin{itemize}
\item Almindelig indlejring af tags skal understøttes. Dette vil vi
  teste ved at bekræfte at de i krav 3.3 beskrevne tags fungerer
  selvom de er indlejret i \texttt{em}-tags.
\item Håndteringen af den implicitte afslutning af
  \textit{block}-tags. \footnote{I HTML er det tilladt ikke at
    afslutte f.eks. \texttt{p}-tags, de opfattes i stedet som implicit
    afsluttede næste gang der bliver åbnet et \textit{block}-tag} Den
  repræsentative side fra denne ækvivalens-klasse indeholder implicit
  afsluttede \texttt{p}-tags, og programmet skal korrekt håndtere
  dette og opdele siden korrekt i afsnit, noget der direkte kan
  aflæses fra output.
\item Tags der ikke behøver afslutning, som \texttt{hr} og
  \texttt{br}, skal håndteres korrekt. En side indeholdende teksten
  \texttt{<br lang=en} i et ellers dansk afsnit ville, hvis
  implementationen var ukorrekt og den på \texttt{br}-tagget følgende
  tekst blev opfattet som børne-elementer af \texttt{br}-tagget, bruge
  engelsk stavekontrol for den følgende tekst, hvilket ville være
  ukorrekt.
\item HTML-entities skal understøttes. Som minimum skal \texttt{\&amp;}
  (ampersand), \texttt{\&gt;} (større-end tegn), \texttt{\&lt;}
  (mindre-end tegn) og de relevantie entities for de danske
  specialtegn (både store og små bogstaver).
\item En side indeholdende tekst i HTML-kommentarer skal analyseres,
  og teksten i kommentarerne skal ikke fremgå af analysen.
\end{itemize}

\section{Krav 8.1: Indkodning}

Undervejs i programmets udvikling skiftede vi SML-implementation fra
Moscow ML til SML/NJ, hvilket også ændrede dette krav. I stedet for at
understøtte Moscow ML's indbyggede indkodning understøtter vi explicit
Latin-1.

\end{landscape}

\chapter{Yderligere funktionstests}

\section{Output--mappe}
Hvis man angiver en output--mappe så skal programmet gemme
resultaterne i denne mappe. Det skal testes at dette sker og at
programmet melder fejl hvis man angiver en allerede eksisterende
mappe. Det skal desuden testes at programmet viser hvor resultatet er
gemt såfremt brugeren ikke selv har angivet en output--mappe.

\section{Ugyldig inddata}
Ved alle de forskellige konfigurationer man kan lave er der mulighed
for at angive noget ugyldigt, f.eks. ved at indtaste tegn hvor der
forventes et tal. Denne test skal afdække om der gives fyldestgørene
fejlmeddelelser i disse tilfælde.



\subsubsection{Baggrund}
Der er ikke stillet krav om dette, men (...)

\chapter{Brugertest}
Brugertesten skal afsløre brugervenlighedsproblemer med vores program
og skal samtidigt bruges til at evaluere detaljeniveauet i vores
brugermanual. Vi vil udføre testen som et tænke-højt forsøg hvor
brugeren skal udføre nogle opgaver og samtidigt fortælle hvad personen
tænker og gør. Vi vil undervejs ikke hjælpe brugeren med ting der
omhandler vores program, men hvis der er spørgsmål til andre ting, så
vil vi gerne hjælpe.

Man kan sige at programmet brugsmæssigt er delt i to. Den ene del
handler om at starte en analyse og den anden del om at aflæse
resultatet. I udførelsen af brugertesten vil vi ikke direkte lave
denne adskillelse, men det er sådan vi vil evaluere resultaterne.

\section{Opgaver}
Dette afsnit indeholder de opgaver vi vil stille brugeren.

\subsection{Opgave 1: Simpel analyse}
\begin{itemize}
\item Sæt en analyse i gang af http://dybber.dk/
\item Åben analyseresultatet når analysen er afsluttet.
\item Hvilken side er den sværeste på hjemmesiden?
\end{itemize}

\subsection{Opgave 2: Analyse med maks. dybde}
\begin{itemize}
\item Start en analyse af http://da.wikipedia.org/ hvor kun forsiden
  analyseres, dvs. der skal ikke følges nogen links.
\item Åben analyseresultatet og klik ind på den analyserede side.
\item Hvad er sidens læsbarhedsindeks/LIX--tal?
\item Er der nogen stavefejl på siden?
\item Er der nogen ord der fejlagtigt er gentaget?
\end{itemize}

\subsection{Opgave 3: Begrænset analyse}
\begin{itemize}
\item Start en analysen på samme måde som sidste opgave, dog skal
  analysen begrænses så HTML--tags med \texttt{id=``column--one''} ikke
  medtages i analysen.
\item Hvad er sidens læsbarhedsindeks nu?
\end{itemize}

\section{Valg af forsøgspersoner}
Til at udføre vores brugertest skal vi bruge en eller flere personer
indenfor vores målgruppe. I kravspecifikationen er vores målgruppe
specificeret som:
\begin{quote}
En person i vores målgruppe er en hjemmesideskribent der er bekendt
med HTML. Personen har en professionel interessere i at teksten er
læsbar, således at vedkommende selv vil sætte sig ind i betydningen af
de udførte analysers resultater.
\end{quote}

I kravspecifikationen står der også at programmet skal være udformet
som et kommandolinjeværktøj og at det skal kunne køre på GNU--baserede
Linux maskiner. Dette stiller herved ét yderligere krav til
forsøgspersonerne: de skal have forudgående kendskab til
kommando\-linje\-baserede programmer.

\section{Afvikling af brugertest}
Onsdag den 6. juni afviklede vi vores brugertest.

\end{document}
